{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from time import time\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "import random, os\n",
    "import numpy as np\n",
    "\n",
    "directorySeparator = \"\\\\\"\n",
    "\n",
    "testImages = \"E:\\\\594_data\\\\smoothmuscle_NN_Data\\\\test_holdout\\\\images\"\n",
    "\n",
    "pericyteMasks = \"E:\\\\594_data\\\\\\pericyte_NN_Data\\\\test_holdout\\\\masks\" \n",
    "smoothmuscleMasks = \"E:\\\\594_data\\\\smoothmuscle_NN_Data\\\\test_holdout\\\\masks\" \n",
    "\n",
    "\n",
    "window_size = 65\n",
    "middle = int(window_size / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_image(img):\n",
    "    height, width = img.shape\n",
    "\n",
    "    #the following creates a mirrored image with the edges mirrored using a size window_size\n",
    "\n",
    "    newImg = np.zeros((height+(window_size*2),width+(window_size*2)), np.uint8)\n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            newImg[h+window_size,w+window_size] = img[h,w]\n",
    "\n",
    "    for w in range(window_size):\n",
    "        for h in range(height):\n",
    "            newImg[h+window_size,w]=img[h,window_size-1-w]\n",
    "            newImg[h+window_size,width+(2*window_size)-1-w]=img[h,width-(window_size-w)]\n",
    "\n",
    "    for h in range(window_size):\n",
    "        for w in range(width):\n",
    "            newImg[h,w+window_size]=img[window_size-1-h,w]\n",
    "            newImg[height+(2*window_size)-1-h,w+window_size]=img[height-(window_size-h),w]\n",
    "            \n",
    "    return newImg\n",
    "    \n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights from disk\n",
      "loaded weights from disk\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(1,65,65 ), data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.load_weights(\"weights.balanced.hdf5\") #best weights for the cell/no-cell classifier?\n",
    "#model.load_weights(\"weights.best.imbalanced.hdf5\")\n",
    "print(\"loaded weights from disk\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=(1,65,65 ), data_format='channels_first'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model2.load_weights(\"weights.distinguisher.hdf5\")\n",
    "\n",
    "print(\"loaded weights from disk\")\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPericyte = 0\n",
    "totalSmoothmuscle = 0\n",
    "totalNoCell = 0\n",
    "\n",
    "totalEverything = 0\n",
    "\n",
    "\n",
    "labelPericytePredictedPericyte = 0\n",
    "labelSmoothPredictedPericyte = 0\n",
    "labelNoCellPredictedPericyte = 0\n",
    "\n",
    "labelPericytePredictedSmooth = 0\n",
    "labelSmoothPredictedSmooth = 0\n",
    "labelNoCellPredictedSmooth = 0\n",
    "\n",
    "labelPericytePredictedNoCell = 0\n",
    "labelSmoothPredictedNoCell = 0\n",
    "labelNoCellPredictedNoCell = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: Amy_4th_Z71-80_2nd_cropped0007.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0018.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0024.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0026.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0028.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0032.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0038.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0040.tif\n",
      "Filename: Amy_4th_Z71-80_2nd_cropped0042.tif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-93c127843220>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;31m#print(crop_img.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[0mcellExistPrediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcellExistPrediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.005\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#if the pixel is classified as having a cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[1;32m-> 1027\u001b[1;33m                                   steps=steps)\n\u001b[0m\u001b[0;32m   1028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1800\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for filename in os.listdir(testImages): #for each file in the test images\n",
    "    if filename.endswith(\".tif\"): \n",
    "        \n",
    "        print(\"Filename: \"+ filename)\n",
    "        \n",
    "        img = cv2.imread(testImages+directorySeparator+filename,-1)\n",
    "        img = (img/256).astype('uint8')\n",
    "        mirror = mirror_image(img)\n",
    "\n",
    "        \n",
    "        pericyteMask = cv2.imread(pericyteMasks+directorySeparator+filename,-1)\n",
    "    \n",
    "        smoothmuscleMask = cv2.imread(smoothmuscleMasks+directorySeparator+filename,-1)\n",
    "    \n",
    "        height,width = img.shape\n",
    "        \n",
    "        for h in range(int(height)): #for each pixel in the image\n",
    "            for w in range(width):\n",
    "                \n",
    "                isPericyte = False\n",
    "                isSmoothMuscle = False\n",
    "                isNoCell = False\n",
    "                \n",
    "                if (pericyteMask[h,w]==255):\n",
    "                    isPericyte = True\n",
    "                    totalPericyte += 1\n",
    "                    #print(\"pericyte present at: \" + str(h) + \",\" +str(w))\n",
    "                \n",
    "                elif (smoothmuscleMask[h,w]==255):\n",
    "                    isSmoothMuscle = True\n",
    "                    totalSmoothmuscle += 1\n",
    "                    #print(\"smooth muscle present at: \" + str(h) + \",\" +str(w))\n",
    "                else:\n",
    "                    isNoCell = True\n",
    "                    totalNoCell += 1\n",
    "                    \n",
    "                totalEverything += 1\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                crop_img = mirror[(h+window_size-middle):(h+window_size+middle+1), (w+window_size-middle):(w+window_size+middle+1)]\n",
    "                #test_array.append([crop_img / (1./255)])\n",
    "                \n",
    "                crop_img = [[crop_img] ]\n",
    "                crop_img = np.array(crop_img)\n",
    "                crop_img = crop_img * (1./255)\n",
    "                #print(crop_img.shape)\n",
    "                \n",
    "                cellExistPrediction = model.predict(crop_img)\n",
    "                \n",
    "                if (cellExistPrediction[0] < 0.005 ): #if the pixel is classified as having a cell\n",
    "                    cellTypePrediction = model2.predict(crop_img)\n",
    "                    \n",
    "                    if (cellTypePrediction < .5): #0 is pericyte, 1 is smoothmuscle, so pericyte first\n",
    "                        if isPericyte:\n",
    "                            labelPericytePredictedPericyte += 1\n",
    "                        if isSmoothMuscle:\n",
    "                            labelSmoothPredictedPericyte += 1\n",
    "                        if isNoCell:\n",
    "                            labelNoCellPredictedPericyte += 1\n",
    "                            #print(\"pericyte detected at: \" + str(h) + \",\" +str(w))\n",
    "                    \n",
    "                    else: #smooth muscle\n",
    "                        if isPericyte:\n",
    "                            labelPericytePredictedSmooth += 1\n",
    "                        if isSmoothMuscle:\n",
    "                            labelSmoothPredictedSmooth += 1\n",
    "                        if isNoCell:\n",
    "                            labelNoCellPredictedSmooth += 1                       \n",
    "                        #print(\"smooth muscle detected at: \" + str(h) + \",\" +str(w))\n",
    "                \n",
    "                else: #pixel has no cell\n",
    "                    if isPericyte:\n",
    "                        labelPericytePredictedNoCell += 1\n",
    "                    if isSmoothMuscle:\n",
    "                        labelSmoothPredictedNoCell += 1\n",
    "                    if isNoCell:\n",
    "                        labelNoCellPredictedNoCell += 1\n",
    "                    \n",
    "        #TODO: test that smooth muscles are correct coordinates based out prints populate the correct incremented variables and output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Everything: 2371734\n",
      "Total Pericyte: 4867\n",
      "Total Smooth Muscle: 8107\n",
      "Total No Cell: 2358760\n",
      "Pericytes predicted Pericytes: 2840\n",
      "Pericytes predicted Smooth muscle: 1505\n",
      "Pericytes predicted No cell: 522\n",
      "Smooth muscle predicted Pericytes: 156\n",
      "Smooth muscle predicted Smooth muscle: 6615\n",
      "Smooth muscle predicted No cell: 1335\n",
      "No cell predicted Pericytes: 2192\n",
      "No cell predicted Smooth muscle: 14271\n",
      "No cell predicted No cell: 2342294\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Everything: \" + str(totalEverything))\n",
    "print(\"Total Pericyte: \" + str(totalPericyte))\n",
    "print(\"Total Smooth Muscle: \" + str(totalSmoothmuscle))\n",
    "print(\"Total No Cell: \" + str(totalNoCell))\n",
    "print(\"Pericytes predicted Pericytes: \" + str(labelPericytePredictedPericyte))\n",
    "print(\"Pericytes predicted Smooth muscle: \" + str(labelPericytePredictedSmooth))\n",
    "print(\"Pericytes predicted No cell: \" + str(labelPericytePredictedNoCell))\n",
    "print(\"Smooth muscle predicted Pericytes: \" + str(labelSmoothPredictedPericyte))\n",
    "print(\"Smooth muscle predicted Smooth muscle: \" + str(labelSmoothPredictedSmooth))\n",
    "print(\"Smooth muscle predicted No cell: \" + str(labelSmoothPredictedNoCell))\n",
    "print(\"No cell predicted Pericytes: \" + str(labelNoCellPredictedPericyte))\n",
    "print(\"No cell predicted Smooth muscle: \" + str(labelNoCellPredictedSmooth))\n",
    "print(\"No cell predicted No cell: \" + str(labelNoCellPredictedNoCell))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
