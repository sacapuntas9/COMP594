{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tyler\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "trainDir = \"E:\\\\594_data\\\\smoothmuscle_NN_Data\\\\train\"\n",
    "validDir = \"E:\\\\594_data\\\\smoothmuscle_NN_Data\\\\valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_score(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
    "    y_correct = y_true * y_pred\n",
    "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
    "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
    "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
    "    precision = sum_correct / sum_pred\n",
    "    recall = sum_correct / sum_true\n",
    "    f_score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
    "    return tf.reduce_mean(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 73051 images belonging to 2 classes.\n",
      "Found 9839 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        data_format='channels_first',\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,         \n",
    "                                  data_format='channels_first'\n",
    "                                 )\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        trainDir,  # this is the target directory\n",
    "        target_size=(65, 65),  # all images will be resized\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validDir,\n",
    "        target_size=(65, 65),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.0705 - binary_accuracy: 0.9814\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.98498, saving model to weights.smoothmuscle.hdf5\n",
      "3750/3750 [==============================] - 1013s 270ms/step - loss: 0.0705 - binary_accuracy: 0.9814 - val_loss: 0.0509 - val_binary_accuracy: 0.9850\n",
      "Epoch 2/10\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0637 - binary_accuracy: 0.9846\n",
      "Epoch 00002: val_binary_accuracy did not improve\n",
      "3750/3750 [==============================] - 51s 14ms/step - loss: 0.0638 - binary_accuracy: 0.9846 - val_loss: 0.0566 - val_binary_accuracy: 0.9849\n",
      "Epoch 3/10\n",
      "3745/3750 [============================>.] - ETA: 0s - loss: 0.0705 - binary_accuracy: 0.9847\n",
      "Epoch 00003: val_binary_accuracy improved from 0.98498 to 0.98561, saving model to weights.smoothmuscle.hdf5\n",
      "3750/3750 [==============================] - 50s 13ms/step - loss: 0.0705 - binary_accuracy: 0.9847 - val_loss: 0.0833 - val_binary_accuracy: 0.9856\n",
      "Epoch 4/10\n",
      "3746/3750 [============================>.] - ETA: 0s - loss: 0.0697 - binary_accuracy: 0.9845\n",
      "Epoch 00004: val_binary_accuracy did not improve\n",
      "3750/3750 [==============================] - 49s 13ms/step - loss: 0.0697 - binary_accuracy: 0.9845 - val_loss: 0.0562 - val_binary_accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "3745/3750 [============================>.] - ETA: 0s - loss: 0.0741 - binary_accuracy: 0.9845\n",
      "Epoch 00005: val_binary_accuracy improved from 0.98561 to 0.98672, saving model to weights.smoothmuscle.hdf5\n",
      "3750/3750 [==============================] - 50s 13ms/step - loss: 0.0743 - binary_accuracy: 0.9845 - val_loss: 0.0554 - val_binary_accuracy: 0.9867\n",
      "Epoch 6/10\n",
      "3746/3750 [============================>.] - ETA: 0s - loss: 0.0790 - binary_accuracy: 0.9839\n",
      "Epoch 00006: val_binary_accuracy did not improve\n",
      "3750/3750 [==============================] - 55s 15ms/step - loss: 0.0789 - binary_accuracy: 0.9839 - val_loss: 0.0483 - val_binary_accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0783 - binary_accuracy: 0.9847- ETA: 1s - \n",
      "Epoch 00007: val_binary_accuracy did not improve\n",
      "3750/3750 [==============================] - 54s 14ms/step - loss: 0.0782 - binary_accuracy: 0.9847 - val_loss: 0.0548 - val_binary_accuracy: 0.9846\n",
      "Epoch 8/10\n",
      "3749/3750 [============================>.] - ETA: 0s - loss: 0.0792 - binary_accuracy: 0.9843\n",
      "Epoch 00008: val_binary_accuracy did not improve\n",
      "3750/3750 [==============================] - 55s 15ms/step - loss: 0.0791 - binary_accuracy: 0.9843 - val_loss: 0.0806 - val_binary_accuracy: 0.9847\n",
      "Epoch 9/10\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0838 - binary_accuracy: 0.9836\n",
      "Epoch 00009: val_binary_accuracy did not improve\n",
      "3750/3750 [==============================] - 51s 14ms/step - loss: 0.0838 - binary_accuracy: 0.9836 - val_loss: 0.0568 - val_binary_accuracy: 0.9853\n",
      "Epoch 10/10\n",
      "3747/3750 [============================>.] - ETA: 0s - loss: 0.0844 - binary_accuracy: 0.9833\n",
      "Epoch 00010: val_binary_accuracy did not improve\n",
      "3750/3750 [==============================] - 54s 14ms/step - loss: 0.0844 - binary_accuracy: 0.9833 - val_loss: 0.0671 - val_binary_accuracy: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238fb641e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(1,65,65 ), data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "#model.add(Activation('softmax'))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Activation('tanh'))\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights.smoothmuscle.hdf5\", verbose=1, monitor='val_binary_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             mode='auto')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  \n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch= 120000 // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps= 16000 // batch_size,\n",
    "        verbose=1, \n",
    "        callbacks=[checkpoint,tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
